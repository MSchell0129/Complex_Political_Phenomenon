{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import keras as kr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>pollster</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>population</th>\n",
       "      <th>politician</th>\n",
       "      <th>favorable</th>\n",
       "      <th>unfavorable</th>\n",
       "      <th>very_favorable</th>\n",
       "      <th>somewhat_favorable</th>\n",
       "      <th>somewhat_unfavorable</th>\n",
       "      <th>very_unfavorable</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114577</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>YouGov</td>\n",
       "      <td>1195</td>\n",
       "      <td>rv</td>\n",
       "      <td>Michael F. Bennet</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114585</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>YouGov</td>\n",
       "      <td>1198</td>\n",
       "      <td>rv</td>\n",
       "      <td>Michael Bloomberg</td>\n",
       "      <td>24.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114589</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>YouGov</td>\n",
       "      <td>1198</td>\n",
       "      <td>rv</td>\n",
       "      <td>Cory A. Booker</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114593</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>YouGov</td>\n",
       "      <td>1198</td>\n",
       "      <td>rv</td>\n",
       "      <td>Steve Bullock</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114597</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>YouGov</td>\n",
       "      <td>1202</td>\n",
       "      <td>rv</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id    end_date pollster  sample_size population  \\\n",
       "0       114577  2019-12-10   YouGov         1195         rv   \n",
       "1       114585  2019-12-10   YouGov         1198         rv   \n",
       "2       114589  2019-12-10   YouGov         1198         rv   \n",
       "3       114593  2019-12-10   YouGov         1198         rv   \n",
       "4       114597  2019-12-10   YouGov         1202         rv   \n",
       "\n",
       "          politician  favorable  unfavorable  very_favorable  \\\n",
       "0  Michael F. Bennet       14.0         29.0             4.0   \n",
       "1  Michael Bloomberg       24.0         58.0             7.0   \n",
       "2     Cory A. Booker       35.0         45.0            11.0   \n",
       "3      Steve Bullock       14.0         27.0             3.0   \n",
       "4     Pete Buttigieg       35.0         44.0            14.0   \n",
       "\n",
       "   somewhat_favorable  somewhat_unfavorable  very_unfavorable  results  \n",
       "0                10.0                  12.0              17.0        0  \n",
       "1                17.0                  20.0              38.0        0  \n",
       "2                24.0                  12.0              33.0        0  \n",
       "3                11.0                  11.0              16.0        0  \n",
       "4                21.0                  13.0              31.0        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polling_df = pd.read_csv('../election_resources/cleaned_2019_data.csv')\n",
    "polling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollster</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>population</th>\n",
       "      <th>politician</th>\n",
       "      <th>favorable</th>\n",
       "      <th>unfavorable</th>\n",
       "      <th>very_favorable</th>\n",
       "      <th>somewhat_favorable</th>\n",
       "      <th>somewhat_unfavorable</th>\n",
       "      <th>very_unfavorable</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouGov</td>\n",
       "      <td>1195</td>\n",
       "      <td>rv</td>\n",
       "      <td>Michael F. Bennet</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YouGov</td>\n",
       "      <td>1198</td>\n",
       "      <td>rv</td>\n",
       "      <td>Michael Bloomberg</td>\n",
       "      <td>24.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YouGov</td>\n",
       "      <td>1198</td>\n",
       "      <td>rv</td>\n",
       "      <td>Cory A. Booker</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YouGov</td>\n",
       "      <td>1198</td>\n",
       "      <td>rv</td>\n",
       "      <td>Steve Bullock</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YouGov</td>\n",
       "      <td>1202</td>\n",
       "      <td>rv</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pollster  sample_size population         politician  favorable  unfavorable  \\\n",
       "0   YouGov         1195         rv  Michael F. Bennet       14.0         29.0   \n",
       "1   YouGov         1198         rv  Michael Bloomberg       24.0         58.0   \n",
       "2   YouGov         1198         rv     Cory A. Booker       35.0         45.0   \n",
       "3   YouGov         1198         rv      Steve Bullock       14.0         27.0   \n",
       "4   YouGov         1202         rv     Pete Buttigieg       35.0         44.0   \n",
       "\n",
       "   very_favorable  somewhat_favorable  somewhat_unfavorable  very_unfavorable  \\\n",
       "0             4.0                10.0                  12.0              17.0   \n",
       "1             7.0                17.0                  20.0              38.0   \n",
       "2            11.0                24.0                  12.0              33.0   \n",
       "3             3.0                11.0                  11.0              16.0   \n",
       "4            14.0                21.0                  13.0              31.0   \n",
       "\n",
       "   results  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polling_df.drop(columns=['question_id', 'end_date'], inplace=True)\n",
    "polling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pollster                 13\n",
       "sample_size             288\n",
       "population                1\n",
       "politician               34\n",
       "favorable                68\n",
       "unfavorable              65\n",
       "very_favorable           49\n",
       "somewhat_favorable       43\n",
       "somewhat_unfavorable     33\n",
       "very_unfavorable         60\n",
       "results                   2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polling_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_size</th>\n",
       "      <th>favorable</th>\n",
       "      <th>unfavorable</th>\n",
       "      <th>very_favorable</th>\n",
       "      <th>somewhat_favorable</th>\n",
       "      <th>somewhat_unfavorable</th>\n",
       "      <th>very_unfavorable</th>\n",
       "      <th>results</th>\n",
       "      <th>pollster_ABC News/Washington Post</th>\n",
       "      <th>pollster_CNN/SSRS</th>\n",
       "      <th>...</th>\n",
       "      <th>politician_Pete Buttigieg</th>\n",
       "      <th>politician_Seth Moulton</th>\n",
       "      <th>politician_Sherrod Brown</th>\n",
       "      <th>politician_Stacey Yvonne Abrams</th>\n",
       "      <th>politician_Steve Bullock</th>\n",
       "      <th>politician_Terry R. McAuliffe</th>\n",
       "      <th>politician_Tim Ryan</th>\n",
       "      <th>politician_Tom Steyer</th>\n",
       "      <th>politician_Tulsi Gabbard</th>\n",
       "      <th>politician_Wayne Messam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1195</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1198</td>\n",
       "      <td>24.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1198</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1198</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1202</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_size  favorable  unfavorable  very_favorable  somewhat_favorable  \\\n",
       "0         1195       14.0         29.0             4.0                10.0   \n",
       "1         1198       24.0         58.0             7.0                17.0   \n",
       "2         1198       35.0         45.0            11.0                24.0   \n",
       "3         1198       14.0         27.0             3.0                11.0   \n",
       "4         1202       35.0         44.0            14.0                21.0   \n",
       "\n",
       "   somewhat_unfavorable  very_unfavorable  results  \\\n",
       "0                  12.0              17.0        0   \n",
       "1                  20.0              38.0        0   \n",
       "2                  12.0              33.0        0   \n",
       "3                  11.0              16.0        0   \n",
       "4                  13.0              31.0        0   \n",
       "\n",
       "   pollster_ABC News/Washington Post  pollster_CNN/SSRS  ...  \\\n",
       "0                                0.0                0.0  ...   \n",
       "1                                0.0                0.0  ...   \n",
       "2                                0.0                0.0  ...   \n",
       "3                                0.0                0.0  ...   \n",
       "4                                0.0                0.0  ...   \n",
       "\n",
       "   politician_Pete Buttigieg  politician_Seth Moulton  \\\n",
       "0                        0.0                      0.0   \n",
       "1                        0.0                      0.0   \n",
       "2                        0.0                      0.0   \n",
       "3                        0.0                      0.0   \n",
       "4                        1.0                      0.0   \n",
       "\n",
       "   politician_Sherrod Brown  politician_Stacey Yvonne Abrams  \\\n",
       "0                       0.0                              0.0   \n",
       "1                       0.0                              0.0   \n",
       "2                       0.0                              0.0   \n",
       "3                       0.0                              0.0   \n",
       "4                       0.0                              0.0   \n",
       "\n",
       "   politician_Steve Bullock  politician_Terry R. McAuliffe  \\\n",
       "0                       0.0                            0.0   \n",
       "1                       0.0                            0.0   \n",
       "2                       0.0                            0.0   \n",
       "3                       1.0                            0.0   \n",
       "4                       0.0                            0.0   \n",
       "\n",
       "   politician_Tim Ryan  politician_Tom Steyer  politician_Tulsi Gabbard  \\\n",
       "0                  0.0                    0.0                       0.0   \n",
       "1                  0.0                    0.0                       0.0   \n",
       "2                  0.0                    0.0                       0.0   \n",
       "3                  0.0                    0.0                       0.0   \n",
       "4                  0.0                    0.0                       0.0   \n",
       "\n",
       "   politician_Wayne Messam  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polling_df = pd.get_dummies(polling_df, dtype=float)\n",
    "polling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "polling_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = polling_df['results'].values\n",
    "X = polling_df.drop(['results'], axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1223, 55)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid', 'leaky_relu', 'elu', 'selu'])\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "                                        min_value=1,\n",
    "                                        max_value=100,\n",
    "                                        step=2), activation=activation, input_dim=len(X_train_scaled[0])))\n",
    "    for i in range(hp.Int('num_layers', 1, 10)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                        min_value=1,\n",
    "                                        max_value=100,\n",
    "                                        step=2), activation=activation))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    loss = hp.Choice('loss', ['binary_crossentropy', 'mse'])\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd', 'adagrad', 'adadelta', 'adamax', 'nadam'])\n",
    "    nn_model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(create_model, objective='val_accuracy', max_epochs=20, hyperband_iterations=10, directory='my_dir2', project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 300 Complete [00h 00m 10s]\n",
      "val_accuracy: 0.9975489974021912\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 32m 52s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled, y_train, epochs=20, validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'first_units': 75,\n",
       " 'num_layers': 8,\n",
       " 'units_0': 15,\n",
       " 'loss': 'mse',\n",
       " 'optimizer': 'adam',\n",
       " 'units_1': 67,\n",
       " 'units_2': 37,\n",
       " 'units_3': 61,\n",
       " 'units_4': 5,\n",
       " 'units_5': 29,\n",
       " 'units_6': 83,\n",
       " 'units_7': 13,\n",
       " 'tuner/epochs': 3,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 2,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 4.2026e-04 - accuracy: 1.0000 - 258ms/epoch - 20ms/step\n",
      "Loss: 0.00042026155279017985, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model against full test data\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 75)                4200      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 15)                1140      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 67)                1072      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 37)                2516      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 61)                2318      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 5)                 310       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 29)                174       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 83)                2490      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,304\n",
      "Trainable params: 14,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_scaled[0])\n",
    "hidden_nodes_layer1 =  75\n",
    "hidden_nodes_layer2 = 15\n",
    "hidden_nodes_layer3 = 67\n",
    "hidden_nodes_layer4 = 37\n",
    "hidden_nodes_layer5 = 61\n",
    "hidden_nodes_layer6 = 5\n",
    "hidden_nodes_layer7 = 29\n",
    "hidden_nodes_layer8 = 83\n",
    "\n",
    "\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer7, activation=\"tanh\"))\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer8, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(output_dim, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 2s 6ms/step - loss: 0.0982 - accuracy: 0.8978\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9975\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.9967\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 9.2852e-04 - accuracy: 0.9992\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 7.5833e-04 - accuracy: 0.9992\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 7.0734e-05 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 5.1504e-05 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.0700e-05 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 3.3281e-05 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.7806e-05 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 2.3694e-05 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.0443e-05 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.7807e-05 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.5692e-05 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.3930e-05 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.2455e-05 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1206e-05 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.0149e-05 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 9.2364e-06 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 8.4330e-06 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 7.7460e-06 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 7.1279e-06 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 6.5842e-06 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 6.0938e-06 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 5.6639e-06 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 5.2793e-06 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 4.9285e-06 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.6129e-06 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.3285e-06 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.0656e-06 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.8273e-06 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.6092e-06 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.4098e-06 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 3.2210e-06 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0476e-06 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 2.8918e-06 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 2.7463e-06 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.6110e-06 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 2.4859e-06 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.3690e-06 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 2.2592e-06 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.1573e-06 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 2.0618e-06 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.9723e-06 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.8879e-06 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.8087e-06 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.7341e-06 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.6632e-06 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.5966e-06 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.5334e-06 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.4737e-06 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.4168e-06 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.3632e-06 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.3119e-06 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.2640e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.2175e-06 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.1734e-06 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.1320e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.0929e-06 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.0543e-06 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.0183e-06 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 9.8407e-07 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 9.5130e-07 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 9.1999e-07 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 8.9017e-07 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 8.6127e-07 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 8.3381e-07 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 8.0734e-07 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 7.8226e-07 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 7.5776e-07 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 7.3418e-07 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 7.1198e-07 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 6.9017e-07 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 6.6958e-07 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 6.4953e-07 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 6.2933e-07 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 6.1072e-07 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 5.9268e-07 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 5.7529e-07 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 5.5893e-07 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 5.4307e-07 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 5.2776e-07 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 5.1299e-07 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.9874e-07 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.8481e-07 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.7152e-07 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 4.5868e-07 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 4.4620e-07 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.3416e-07 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.2270e-07 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 4.1119e-07 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 4.0024e-07 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.8970e-07 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 3.7956e-07 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 3.6968e-07 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.6022e-07 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.5087e-07 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 3.4185e-07 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 3.3308e-07 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.2470e-07 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100, initial_epoch= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 1.5562e-04 - accuracy: 1.0000 - 205ms/epoch - 16ms/step\n",
      "Loss: 0.00015562385669909418, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.1197333e-04],\n",
       "       [4.6341945e-04],\n",
       "       [1.3908128e-03],\n",
       "       [4.0480919e-04],\n",
       "       [3.9984228e-04],\n",
       "       [4.3444408e-04],\n",
       "       [4.1480301e-04],\n",
       "       [4.1885694e-04],\n",
       "       [4.8474417e-04],\n",
       "       [4.2000666e-04],\n",
       "       [4.1685175e-04],\n",
       "       [4.2314368e-04],\n",
       "       [9.9906045e-01],\n",
       "       [4.0235251e-04],\n",
       "       [4.0250769e-04],\n",
       "       [5.1099213e-04],\n",
       "       [4.1465749e-04],\n",
       "       [3.9807984e-04],\n",
       "       [9.9908471e-01],\n",
       "       [9.9906939e-01],\n",
       "       [4.2811740e-04],\n",
       "       [4.4406214e-04],\n",
       "       [4.0650394e-04],\n",
       "       [3.9588058e-04],\n",
       "       [5.5757444e-04],\n",
       "       [4.2209524e-04],\n",
       "       [4.3801405e-04],\n",
       "       [9.9894220e-01],\n",
       "       [3.9921503e-04],\n",
       "       [4.9630716e-04],\n",
       "       [4.9315824e-04],\n",
       "       [4.0235903e-04],\n",
       "       [4.0891208e-04],\n",
       "       [4.1978111e-04],\n",
       "       [4.1585334e-04],\n",
       "       [4.4045885e-04],\n",
       "       [4.0182602e-04],\n",
       "       [9.9905723e-01],\n",
       "       [4.0477928e-04],\n",
       "       [4.0505914e-04],\n",
       "       [4.0441117e-04],\n",
       "       [4.2509404e-04],\n",
       "       [4.5861924e-04],\n",
       "       [4.7798894e-04],\n",
       "       [4.6908850e-04],\n",
       "       [4.2717147e-04],\n",
       "       [4.2309915e-04],\n",
       "       [4.2955947e-04],\n",
       "       [9.6000207e-04],\n",
       "       [4.4755405e-04],\n",
       "       [4.0207742e-04],\n",
       "       [4.1847941e-04],\n",
       "       [4.1776276e-04],\n",
       "       [4.1821640e-04],\n",
       "       [4.5358701e-04],\n",
       "       [5.1317521e-04],\n",
       "       [9.9908733e-01],\n",
       "       [4.5022651e-04],\n",
       "       [9.9889958e-01],\n",
       "       [4.1501538e-04],\n",
       "       [5.0700962e-04],\n",
       "       [4.0828844e-04],\n",
       "       [4.2856557e-04],\n",
       "       [4.1214126e-04],\n",
       "       [4.5590504e-04],\n",
       "       [6.4492604e-04],\n",
       "       [4.4731944e-04],\n",
       "       [3.9523479e-04],\n",
       "       [4.1074536e-04],\n",
       "       [4.2030850e-04],\n",
       "       [4.3065829e-04],\n",
       "       [4.1948594e-04],\n",
       "       [4.1154624e-04],\n",
       "       [4.9672317e-04],\n",
       "       [9.9909174e-01],\n",
       "       [5.1097997e-04],\n",
       "       [4.1706185e-04],\n",
       "       [4.0167550e-04],\n",
       "       [4.3513271e-04],\n",
       "       [9.9909389e-01],\n",
       "       [4.2574515e-04],\n",
       "       [4.0088731e-04],\n",
       "       [4.6193777e-04],\n",
       "       [4.4575389e-04],\n",
       "       [9.9908471e-01],\n",
       "       [4.3847025e-04],\n",
       "       [9.9904674e-01],\n",
       "       [4.2025620e-04],\n",
       "       [4.5210961e-04],\n",
       "       [5.1006296e-04],\n",
       "       [4.0619212e-04],\n",
       "       [4.0301334e-04],\n",
       "       [4.2337488e-04],\n",
       "       [4.1853986e-04],\n",
       "       [4.2011481e-04],\n",
       "       [9.9908423e-01],\n",
       "       [4.1120211e-04],\n",
       "       [4.3447097e-04],\n",
       "       [4.0293747e-04],\n",
       "       [4.1210727e-04],\n",
       "       [4.5699786e-04],\n",
       "       [4.0058166e-04],\n",
       "       [5.0229894e-04],\n",
       "       [4.0511705e-04],\n",
       "       [4.0246680e-04],\n",
       "       [4.0667391e-04],\n",
       "       [4.2790425e-04],\n",
       "       [9.9905890e-01],\n",
       "       [4.0486382e-04],\n",
       "       [4.7198983e-04],\n",
       "       [4.2129768e-04],\n",
       "       [4.3465346e-04],\n",
       "       [9.9909389e-01],\n",
       "       [4.0695156e-04],\n",
       "       [6.5284583e-04],\n",
       "       [4.1608079e-04],\n",
       "       [4.3981691e-04],\n",
       "       [9.9909139e-01],\n",
       "       [4.3261066e-04],\n",
       "       [4.2778536e-04],\n",
       "       [4.4000964e-04],\n",
       "       [4.0286736e-04],\n",
       "       [4.7560080e-04],\n",
       "       [9.9908221e-01],\n",
       "       [4.2107727e-04],\n",
       "       [4.1884359e-04],\n",
       "       [4.0675901e-04],\n",
       "       [4.1840223e-04],\n",
       "       [4.0797549e-04],\n",
       "       [4.0812968e-04],\n",
       "       [9.9909091e-01],\n",
       "       [7.2473940e-04],\n",
       "       [4.1433581e-04],\n",
       "       [4.0022994e-04],\n",
       "       [4.4250034e-04],\n",
       "       [4.0123847e-04],\n",
       "       [9.9859673e-01],\n",
       "       [3.9801517e-04],\n",
       "       [6.4645335e-04],\n",
       "       [9.9905235e-01],\n",
       "       [4.0814761e-04],\n",
       "       [4.1584027e-04],\n",
       "       [3.9655555e-04],\n",
       "       [5.1912246e-04],\n",
       "       [3.9416205e-04],\n",
       "       [4.0355828e-04],\n",
       "       [4.1184612e-04],\n",
       "       [4.1466596e-04],\n",
       "       [4.9057719e-04],\n",
       "       [4.8812880e-04],\n",
       "       [4.0323814e-04],\n",
       "       [4.2203811e-04],\n",
       "       [4.0355482e-04],\n",
       "       [4.3790345e-04],\n",
       "       [4.1692730e-04],\n",
       "       [4.1566414e-04],\n",
       "       [4.3097138e-04],\n",
       "       [4.0771594e-04],\n",
       "       [3.9723070e-04],\n",
       "       [7.4603147e-04],\n",
       "       [4.7019313e-04],\n",
       "       [3.9107987e-04],\n",
       "       [5.1736989e-04],\n",
       "       [4.1101186e-04],\n",
       "       [5.0733954e-04],\n",
       "       [4.2521462e-04],\n",
       "       [4.0892046e-04],\n",
       "       [3.9632857e-04],\n",
       "       [4.0379399e-04],\n",
       "       [4.2183438e-04],\n",
       "       [4.0246817e-04],\n",
       "       [9.9909198e-01],\n",
       "       [4.1439076e-04],\n",
       "       [4.2225077e-04],\n",
       "       [4.4575200e-04],\n",
       "       [9.9895442e-01],\n",
       "       [4.6740510e-04],\n",
       "       [4.1029372e-04],\n",
       "       [3.9002474e-04],\n",
       "       [4.3453745e-04],\n",
       "       [4.8931950e-04],\n",
       "       [4.0827287e-04],\n",
       "       [4.8632605e-04],\n",
       "       [2.6904061e-03],\n",
       "       [6.4231351e-04],\n",
       "       [4.8231639e-04],\n",
       "       [9.9909425e-01],\n",
       "       [9.9908602e-01],\n",
       "       [4.0195324e-04],\n",
       "       [4.0433847e-04],\n",
       "       [4.4315762e-04],\n",
       "       [4.2481208e-04],\n",
       "       [3.9867079e-04],\n",
       "       [9.9908423e-01],\n",
       "       [4.1392707e-04],\n",
       "       [4.1886693e-04],\n",
       "       [5.2396220e-04],\n",
       "       [4.2217734e-04],\n",
       "       [4.2964114e-04],\n",
       "       [4.1688353e-04],\n",
       "       [4.5614870e-04],\n",
       "       [4.0579884e-04],\n",
       "       [4.5738375e-04],\n",
       "       [4.3533125e-04],\n",
       "       [4.8334245e-04],\n",
       "       [4.1452845e-04],\n",
       "       [2.5165179e-01],\n",
       "       [3.9903561e-04],\n",
       "       [4.0795386e-04],\n",
       "       [4.1384774e-04],\n",
       "       [6.4986548e-04],\n",
       "       [4.0044100e-04],\n",
       "       [4.2889168e-04],\n",
       "       [9.9909174e-01],\n",
       "       [4.5140591e-04],\n",
       "       [3.9858243e-04],\n",
       "       [9.0059941e-04],\n",
       "       [4.7479247e-04],\n",
       "       [4.0445317e-04],\n",
       "       [4.9007690e-04],\n",
       "       [7.6018291e-04],\n",
       "       [4.2458536e-04],\n",
       "       [4.2801540e-04],\n",
       "       [4.6293309e-04],\n",
       "       [4.4587519e-04],\n",
       "       [4.1701036e-04],\n",
       "       [4.9537164e-04],\n",
       "       [4.6112869e-04],\n",
       "       [4.7800053e-04],\n",
       "       [9.9899238e-01],\n",
       "       [4.9794890e-04],\n",
       "       [4.1024169e-04],\n",
       "       [4.2298241e-04],\n",
       "       [4.0409036e-04],\n",
       "       [3.9769866e-04],\n",
       "       [4.1827085e-04],\n",
       "       [4.2857821e-04],\n",
       "       [4.2827881e-04],\n",
       "       [3.9974204e-04],\n",
       "       [4.0779621e-04],\n",
       "       [9.9901676e-01],\n",
       "       [4.0881737e-04],\n",
       "       [6.4459385e-04],\n",
       "       [4.0302525e-04],\n",
       "       [9.9906641e-01],\n",
       "       [4.4467277e-04],\n",
       "       [4.0426600e-04],\n",
       "       [4.8386730e-04],\n",
       "       [4.2880294e-04],\n",
       "       [4.0170079e-04],\n",
       "       [4.0534188e-04],\n",
       "       [5.0580211e-04],\n",
       "       [4.1529263e-04],\n",
       "       [5.0243753e-04],\n",
       "       [4.2019470e-04],\n",
       "       [4.2909369e-04],\n",
       "       [9.9905699e-01],\n",
       "       [4.4213710e-04],\n",
       "       [9.9908948e-01],\n",
       "       [4.1278219e-04],\n",
       "       [4.5578121e-04],\n",
       "       [4.0913996e-04],\n",
       "       [4.5146234e-04],\n",
       "       [4.2470396e-04],\n",
       "       [4.1776735e-04],\n",
       "       [4.1586446e-04],\n",
       "       [5.0880696e-04],\n",
       "       [4.2399950e-04],\n",
       "       [4.2130009e-04],\n",
       "       [4.0313113e-04],\n",
       "       [4.4958320e-04],\n",
       "       [9.9478877e-01],\n",
       "       [4.1300853e-04],\n",
       "       [7.4452051e-04],\n",
       "       [9.9909425e-01],\n",
       "       [4.0459065e-04],\n",
       "       [4.4962607e-04],\n",
       "       [9.9909258e-01],\n",
       "       [4.0547948e-04],\n",
       "       [4.0790314e-04],\n",
       "       [4.3668645e-04],\n",
       "       [9.9907994e-01],\n",
       "       [4.1907106e-04],\n",
       "       [4.1287878e-04],\n",
       "       [9.9908233e-01],\n",
       "       [4.3077877e-04],\n",
       "       [9.9908435e-01],\n",
       "       [4.0078259e-04],\n",
       "       [9.9905902e-01],\n",
       "       [4.5814321e-04],\n",
       "       [6.3629670e-04],\n",
       "       [4.1050010e-04],\n",
       "       [4.2885696e-04],\n",
       "       [3.9929853e-04],\n",
       "       [4.7560671e-04],\n",
       "       [9.9909282e-01],\n",
       "       [9.9897528e-01],\n",
       "       [4.0561962e-04],\n",
       "       [4.5320042e-04],\n",
       "       [4.0939965e-04],\n",
       "       [4.0832019e-04],\n",
       "       [4.1544408e-04],\n",
       "       [9.9900901e-01],\n",
       "       [4.1323472e-04],\n",
       "       [4.2152646e-04],\n",
       "       [4.7452829e-04],\n",
       "       [4.1291438e-04],\n",
       "       [4.4768208e-04],\n",
       "       [5.1293243e-04],\n",
       "       [9.9905676e-01],\n",
       "       [4.5549910e-04],\n",
       "       [9.9906045e-01],\n",
       "       [4.5249567e-04],\n",
       "       [3.9488703e-04],\n",
       "       [9.9908471e-01],\n",
       "       [4.9421116e-04],\n",
       "       [4.0277367e-04],\n",
       "       [4.4439791e-04],\n",
       "       [4.4345637e-04],\n",
       "       [4.2186535e-04],\n",
       "       [4.1285736e-04],\n",
       "       [4.3011815e-04],\n",
       "       [2.4595768e-03],\n",
       "       [4.1581751e-04],\n",
       "       [4.4522117e-04],\n",
       "       [4.1466046e-04],\n",
       "       [3.9347223e-04],\n",
       "       [9.9909604e-01],\n",
       "       [4.1386788e-04],\n",
       "       [4.8931624e-04],\n",
       "       [9.9909008e-01],\n",
       "       [4.1965593e-04],\n",
       "       [4.5709062e-04],\n",
       "       [9.9897158e-01],\n",
       "       [9.9908471e-01],\n",
       "       [4.0869540e-04],\n",
       "       [4.0092095e-04],\n",
       "       [9.9905831e-01],\n",
       "       [4.0982664e-04],\n",
       "       [4.2103307e-04],\n",
       "       [9.9905807e-01],\n",
       "       [4.1886594e-04],\n",
       "       [4.8519537e-04],\n",
       "       [9.9908125e-01],\n",
       "       [9.9908376e-01],\n",
       "       [4.9076288e-04],\n",
       "       [4.1545043e-04],\n",
       "       [4.0871685e-04],\n",
       "       [4.2108950e-04],\n",
       "       [9.9909520e-01],\n",
       "       [4.8828445e-04],\n",
       "       [4.0117613e-04],\n",
       "       [6.0370192e-04],\n",
       "       [5.2839576e-04],\n",
       "       [9.9904305e-01],\n",
       "       [4.1921026e-04],\n",
       "       [6.1952975e-04],\n",
       "       [4.0822793e-04],\n",
       "       [4.1436550e-04],\n",
       "       [9.9908340e-01],\n",
       "       [4.2420992e-04],\n",
       "       [4.3647690e-04],\n",
       "       [3.9264394e-04],\n",
       "       [4.0761160e-04],\n",
       "       [5.2306423e-04],\n",
       "       [4.9788435e-04],\n",
       "       [4.6929848e-04],\n",
       "       [4.7927073e-04],\n",
       "       [4.1268126e-04],\n",
       "       [9.9908376e-01],\n",
       "       [7.4251951e-04],\n",
       "       [4.0723311e-04],\n",
       "       [4.0105588e-04],\n",
       "       [4.6936428e-04],\n",
       "       [4.0138175e-04],\n",
       "       [4.9767626e-04],\n",
       "       [9.9906975e-01],\n",
       "       [4.0166843e-04],\n",
       "       [4.2782738e-04],\n",
       "       [4.0713744e-04],\n",
       "       [4.5682312e-04],\n",
       "       [4.0205132e-04],\n",
       "       [4.2085972e-04],\n",
       "       [3.9237604e-04],\n",
       "       [4.9968337e-04],\n",
       "       [4.2627755e-04],\n",
       "       [4.1468992e-04],\n",
       "       [9.9905616e-01],\n",
       "       [9.9905711e-01],\n",
       "       [9.9905354e-01],\n",
       "       [4.0265679e-04],\n",
       "       [5.4450822e-04],\n",
       "       [4.1603655e-04],\n",
       "       [4.9170217e-04],\n",
       "       [4.3501015e-04],\n",
       "       [6.5424253e-04],\n",
       "       [4.7971954e-04],\n",
       "       [4.5322353e-04],\n",
       "       [4.0115201e-04],\n",
       "       [5.0132745e-04],\n",
       "       [4.3512945e-04],\n",
       "       [3.9931058e-04],\n",
       "       [4.1433368e-04],\n",
       "       [4.1251487e-04],\n",
       "       [4.8990030e-04],\n",
       "       [9.9908352e-01],\n",
       "       [7.6841819e-04],\n",
       "       [4.3688877e-04]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save('trained_model_president.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
